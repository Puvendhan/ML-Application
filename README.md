# ğŸš€ ML App - Iris Classifier
A containerized ML microservice to classify Iris species using FastAPI, Kubernetes, and CI/CD pipelines.

[ğŸ”— GitHub Repository](https://github.com/Puvendhan/ml-app)

This project demonstrates how to train, package, deploy, and observe a simple Scikit-learn ML model using best practice in MLOps. It includes:

- A training pipeline that generates a serialised model and preprocessing pipeline.
- A FastAPI-based inference microservice.
- Kubernetes deployment with CI/CD.
- Observability with Prometheus and Loki.

---

## ğŸ“ Project Structure

```bash
â¯ tree
.
â”œâ”€â”€ app
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ k8s
â”‚   â”œâ”€â”€ actionRunners.yaml
â”‚   â”œâ”€â”€ helm
â”‚   â”‚   â”œâ”€â”€ Chart.yaml
â”‚   â”‚   â”œâ”€â”€ templates
â”‚   â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ gcp-sa-secret.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ hpa.yaml
â”‚   â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â”‚   â”œâ”€â”€ values.yaml
â”‚   â”‚   â”œâ”€â”€ valuesProduction.yaml
â”‚   â”‚   â””â”€â”€ valuesStaging.yaml
â”‚   â””â”€â”€ ingress.yaml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ integration
â”‚   â”‚   â””â”€â”€ test_endpoints.py
â”‚   â””â”€â”€ unit
â”‚       â””â”€â”€ test_api.py
â”œâ”€â”€ train.py
â””â”€â”€ VERSION
```
---

## 1ï¸âƒ£ How to Run the Training Pipeline

### âœ… Recommended: GitHub Actions (`ml-train.yml`)
- Automatically trains the model on push/dispatch.
- Serialises the `Pipeline` object with preprocessing + model.
- Uploads to a remote artifact store (e.g., Google Cloud Storage or GitHub release).

## 2ï¸âƒ£ How to Build and Run the Inference Microservice

### ğŸ”§ CI/CD via GitHub Actions
- ml-app-ci.yml: Runs tests, builds the Docker image, and pushes to a GCR (google container registry).

- ml-deploy.yml: Deploys Kubernetes manifests (Helm based) of the ml app into your gke cluster.



âœ… CI/CD is fully automated from code commit to live deployment.

Snippet

![alt text](image-4.png)

## 3ï¸âƒ£ How to Test the Microservice
ğŸ” Port-forward

```bash
kubectl port-forward svc/ml-api-service 8000:80 -n ml-app
```

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2}'
```

Snippet

![alt text](image-1.png)


## 4ï¸âƒ£ Design
### ğŸ” Consistent Training and Inference

### âš¡ FastAPI Microservice
- FastAPI for async support and auto-generated Swagger docs.
- Built-in /health and /metrics endpoints.

Snippet

![alt text](image-2.png)

### ğŸ§ª CI/CD
- GitHub Actions automate training, testing, building, and deployment.

- Separation of pipelines (ml-train.yml, ml-app-ci.yml, ml-deploy.yml) for maintainability.

## ğŸ“Š Observability

### Prometheus-compatible metrics via prometheus_fastapi_instrumentator.

Deployed the Prometheus into GKE cluster and added the scrape config for the ml app

```bash
    scrape_configs:
    - job_name: 'ml-api'
      static_configs:
      - targets: ['ml-api-service.ml-app.svc.cluster.local:80']
```

### Accessing the Prometheus endpoint using port-forward and it listens on localhost:9090

```bash
kubectl port-forward -n prometheus svc/prometheus-server 9090:80 
```
Snippet
![alt text](image.png)

### There are different approaches for logging (Loki+Promtail/Opentelemetry/ELK)
Loki + Promtail for structured logging of every request.


### Deploy Promtail
Promtail is an agent which collects the logs,runs as a DaemonSet 
Pushes logs to Loki using HTTP.

### Deploy Loki which collects, stores, and queries logs.
- Stores logs in object storage GCS which can be updated in the ConfigMap.
- Loki helm chart to deploy in K8s cluster

```bash
helm repo add grafana https://grafana.github.io/helm-charts
helm install --values values.yaml loki grafana/loki
```

### Deploy Grafana

- Grafana dashboards for real-time monitoring and logging.
- Add the Data Sources for the Prometheus and Loki
- Create Dashboards for various metrics

```bash
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
helm install grafana grafana/grafana \
  --namespace monitoring --create-namespace \
  --set adminPassword='admin' \
  --set service.type=ClusterIP
```


## âœ… Recommendations

### ğŸ”„ GitOps - ArgoCD
- Adopt a GitOps workflow to manage your Kubernetes infrastructure declaratively.
- This enables version control, automated deployment rollbacks, and auditability.
- ArgoRollouts to implement progressive delivery strategies like Canary deployments & Blue-green deployments

### Blog - https://github.com/Puvendhan/gitops
- Explains deploying the Argo rollouts with Canary & Blue-green strategies
- Keda (AutoScaling based on events)
- ML workloads often need to scale based on Request rate (e.g., spike in /predict calls)
- If /predict endpoint exceeds 100 requests/min, scale up.
-  Based on Prometheus metrics like:
```bash
http_requests_total on /predict
inference_latency or failure count
```

### ğŸ” Istio (Service Mesh for Zero Trust and MTLS)
- Manages the secure communication between the pods using mutual TLS (mTLS). Istio injects a sidecar proxy container in each workload.
- Istio sidecar proxies (Envoy) are automatically injected into pods to Encrypt pod-to-pod traffic
- Kiali dashboard visualises the realtime traffic between the pods,namespaces..etc.

TLS, Ingress, scaling, and versioning integrated.